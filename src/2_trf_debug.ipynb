{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None (1536, 321) 330.57333\n",
      "None (1536, 321) 14736.917\n",
      "None (1536, 321) 14736.917\n",
      "None (1536, 321) 17337.0\n"
     ]
    }
   ],
   "source": [
    "import arrayfire as af\n",
    "module_input_1 = af.array.read_array(\"OUTPUT.arr\", key=\"trf_input_0\").to_ndarray()\n",
    "module_output_1 = af.array.read_array(\"OUTPUT.arr\", key=\"trf_output_0\").to_ndarray()\n",
    "module_input_2 = af.array.read_array(\"OUTPUT.arr\", key=\"trf_input_1\").to_ndarray()\n",
    "module_output_2 = af.array.read_array(\"OUTPUT.arr\", key=\"trf_output_2\").to_ndarray()\n",
    "def valueprint(arr, key=None):\n",
    "    print(key, arr.shape, arr.sum())\n",
    "\n",
    "valueprint(module_input_1)\n",
    "valueprint(module_output_1)\n",
    "valueprint(module_input_2)\n",
    "valueprint(module_output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCTCForCTC(\n",
       "  (mctc): MCTCModel(\n",
       "    (encoder): MCTCEncoder(\n",
       "      (layer_norm): MCTCLayerNorm()\n",
       "      (conv): Conv1dSubsampler(\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(80, 3072, kernel_size=(7,), stride=(3,), padding=valid)\n",
       "        )\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (24): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (25): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (26): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (27): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (28): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (29): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (30): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (31): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (32): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (33): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (34): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (35): MCTCLayer(\n",
       "          (intermediate): MCTCIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=False)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (attention): MCTCAttention(\n",
       "            (self): MCTCSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "              (distance_embedding): Embedding(1839, 384)\n",
       "            )\n",
       "            (output): MCTCSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (LayerNorm): MCTCLayerNorm()\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (output): MCTCOutput(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=False)\n",
       "            (LayerNorm): MCTCLayerNorm()\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ctc_head): Linear(in_features=1536, out_features=8065, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing after fixing the model & weights\n",
    "import torch\n",
    "from transformers import MCTCForCTC, MCTCProcessor, MCTCConfig\n",
    "config = MCTCConfig()\n",
    "model = MCTCForCTC(config)\n",
    "model.load_state_dict(torch.load(\"./ported_pytorch_model.bin\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "first_layer = model.mctc.encoder.layers[0]\n",
    "second_layer = model.mctc.encoder.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([1, 321, 1536]) tensor(330.5734)\n",
      "\n",
      "our_output_1 torch.Size([1, 321, 1536]) tensor(14504.3711, grad_fn=<SumBackward0>)\n",
      "module_output_1 (1536, 321) 14736.917\n",
      "\n",
      "our_output_2 torch.Size([1, 321, 1536]) tensor(12090.7656, grad_fn=<SumBackward0>)\n",
      "module_output_2 (1536, 321) 17337.0\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "our_output = torch.Tensor(module_input_1).unsqueeze(0).transpose(1, 2)\n",
    "valueprint(our_output, \"input\")\n",
    "print()\n",
    "our_output = first_layer(our_output)[0]\n",
    "valueprint(our_output, \"our_output_1\")\n",
    "valueprint(module_output_1, \"module_output_1\")\n",
    "print()\n",
    "our_output = second_layer(our_output)[0]\n",
    "valueprint(our_output, \"our_output_2\")\n",
    "valueprint(module_output_2, \"module_output_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL: layer_h_preln\n",
      "FAIL: MHAttention_mask\n",
      "FAIL: MHAttention_mask_scores\n",
      "dict_keys(['selfAttention_input', 'selfAttention_posEmb', 'selfAttention_mask', 'selfAttention_result', 'selfAttention_result_2', 'layer_x', 'layer_h', 'MHAttention_query', 'MHAttention_key', 'MHAttention_value', 'MHAttention_q', 'MHAttention_k', 'MHAttention_v', 'MHAttention_scores', 'MHAttention_pscores', 'MHAttention_pscores_scores', 'MHAttention_padMaskTile', 'MHAttention_padMaskTile_scores', 'MHAttention_result', 'MHAttention_result_attn', 'MHAttention_result_result', 'MHAttention_result_result_2'])\n"
     ]
    }
   ],
   "source": [
    "# lets take a deeper look.\n",
    "import arrayfire as af\n",
    "possib_keys = [\"selfAttention_input\", \"selfAttention_posEmb\", \"selfAttention_mask\", \"selfAttention_result\", \"selfAttention_result_2\",\n",
    "\"layer_x\", \"layer_h_preln\", \"layer_h\", \"MHAttention_query\", \"MHAttention_key\", \"MHAttention_value\", \"MHAttention_q\", \"MHAttention_k\", \"MHAttention_v\",\n",
    "\"MHAttention_scores\", \"MHAttention_pscores\", \"MHAttention_pscores_scores\", \"MHAttention_mask\", \"MHAttention_mask_scores\", \"MHAttention_padMaskTile\", \"MHAttention_padMaskTile_scores\",\n",
    "\"MHAttention_result\", \"MHAttention_result_attn\", \"MHAttention_result_result\", \"MHAttention_result_result_2\"]\n",
    "trf_outputs = {}\n",
    "for key in possib_keys:\n",
    "    try:\n",
    "        value = af.array.read_array(\"OUTPUT_TRF.arr\", key=key).to_ndarray()\n",
    "        trf_outputs[key] = value\n",
    "    except:\n",
    "        print(\"FAIL:\", key)\n",
    "\n",
    "def valueprint(arr, key=None):\n",
    "    print(key, arr.shape, arr.sum())\n",
    "\n",
    "print(trf_outputs.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfAttention_input (1536, 321) 330.57333\n",
      "selfAttention_posEmb (1839, 384, 4) -1679.4205\n",
      "selfAttention_mask (321,) 0.0\n",
      "MHAttention_query (321, 1536) 5019.3354\n",
      "MHAttention_key (321, 1536) -1448.2941\n",
      "MHAttention_value (321, 1536) -995.127\n",
      "MHAttention_q (321, 384, 4) 256.14188\n",
      "MHAttention_k (321, 384, 4) -1448.2941\n",
      "MHAttention_v (321, 384, 4) -995.127\n",
      "selfAttention_result (321, 1536) -1017.8952\n",
      "selfAttention_result_2 (1536, 321) 25.706522\n"
     ]
    }
   ],
   "source": [
    "selfAttention_input = trf_outputs[\"selfAttention_input\"]\n",
    "selfAttention_posEmb = trf_outputs[\"selfAttention_posEmb\"]\n",
    "selfAttention_mask = trf_outputs[\"selfAttention_mask\"]\n",
    "\n",
    "MHAttention_query = trf_outputs[\"MHAttention_query\"]\n",
    "MHAttention_key = trf_outputs[\"MHAttention_key\"]\n",
    "MHAttention_value = trf_outputs[\"MHAttention_value\"]\n",
    "MHAttention_q = trf_outputs[\"MHAttention_q\"]\n",
    "MHAttention_k = trf_outputs[\"MHAttention_k\"]\n",
    "MHAttention_v = trf_outputs[\"MHAttention_v\"]\n",
    "MHAttention_scores = trf_outputs[\"MHAttention_scores\"]\n",
    "MHAttention_pscores = trf_outputs[\"MHAttention_pscores\"]\n",
    "MHAttention_pscores_scores = trf_outputs[\"MHAttention_pscores_scores\"]\n",
    "\n",
    "selfAttention_result = trf_outputs[\"selfAttention_result\"]\n",
    "selfAttention_result_2 = trf_outputs[\"selfAttention_result_2\"]\n",
    "\n",
    "valueprint(selfAttention_input, \"selfAttention_input\")\n",
    "valueprint(selfAttention_posEmb, \"selfAttention_posEmb\")\n",
    "valueprint(selfAttention_mask, \"selfAttention_mask\")\n",
    "\n",
    "valueprint(MHAttention_query, \"MHAttention_query\")\n",
    "valueprint(MHAttention_key, \"MHAttention_key\")\n",
    "valueprint(MHAttention_value, \"MHAttention_value\")\n",
    "valueprint(MHAttention_q, \"MHAttention_q\")\n",
    "valueprint(MHAttention_k, \"MHAttention_k\")\n",
    "valueprint(MHAttention_v, \"MHAttention_v\")\n",
    "\n",
    "valueprint(selfAttention_result, \"selfAttention_result\")\n",
    "valueprint(selfAttention_result_2, \"selfAttention_result_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCTCSelfAttention(\n",
       "  (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "  (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "  (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (distance_embedding): Embedding(1839, 384)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing after fixing the model & weights\n",
    "import torch\n",
    "from transformers import MCTCForCTC, MCTCProcessor, MCTCConfig\n",
    "config = MCTCConfig()\n",
    "model = MCTCForCTC(config)\n",
    "model.load_state_dict(torch.load(\"./ported_pytorch_model.bin\"))\n",
    "model = model.eval()\n",
    "our_selfattn = model.mctc.encoder.layers[0].attention.self\n",
    "our_selfattn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None torch.Size([1, 321, 1536]) tensor(330.5734)\n",
      "query_layer torch.Size([1, 4, 321, 384]) tensor(256.1419, grad_fn=<SumBackward0>)\n",
      "key_layer torch.Size([1, 4, 321, 384]) tensor(-1448.2943, grad_fn=<SumBackward0>)\n",
      "value_layer torch.Size([1, 4, 321, 384]) tensor(-995.1271, grad_fn=<SumBackward0>)\n",
      "attention_scores torch.Size([1, 4, 321, 321]) tensor(30256.4258, grad_fn=<SumBackward0>)\n",
      "positional_embedding torch.Size([321, 321, 384]) tensor(101717.8359, grad_fn=<SumBackward0>)\n",
      "relative_position_scores torch.Size([1, 4, 321, 321]) tensor(57733.4141, grad_fn=<SumBackward0>)\n",
      "attention_scores torch.Size([1, 4, 321, 321]) tensor(87989.8203, grad_fn=<SumBackward0>)\n",
      "attention_probs torch.Size([1, 4, 321, 321]) tensor(1283.9999, grad_fn=<SumBackward0>)\n",
      "None torch.Size([1, 321, 1536]) tensor(-1023.2032, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "our_selfattn_output = torch.Tensor(selfAttention_input).unsqueeze(0).transpose(1, 2)\n",
    "valueprint(our_selfattn_output)\n",
    "our_selfattn_output = our_selfattn(our_selfattn_output)[0]\n",
    "valueprint(our_selfattn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHAttention_q (321, 384, 4) 256.14188\n",
      "MHAttention_k (321, 384, 4) -1448.2941\n",
      "MHAttention_v (321, 384, 4) -995.127\n",
      "MHAttention_scores (321, 321, 4) 30256.422\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Up to Q,K,V checks out:\n",
    "query_layer torch.Size([1, 4, 321, 384]) tensor(256.1419, grad_fn=<SumBackward0>)\n",
    "key_layer torch.Size([1, 4, 321, 384]) tensor(-1448.2943, grad_fn=<SumBackward0>)\n",
    "value_layer torch.Size([1, 4, 321, 384]) tensor(-995.1271, grad_fn=<SumBackward0>)\n",
    "attention_scores torch.Size([1, 4, 321, 321]) tensor(30256.4258, grad_fn=<SumBackward0>)\n",
    "'''\n",
    "valueprint(MHAttention_q, \"MHAttention_q\")\n",
    "valueprint(MHAttention_k, \"MHAttention_k\")\n",
    "valueprint(MHAttention_v, \"MHAttention_v\")\n",
    "valueprint(MHAttention_scores, \"MHAttention_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHAttention_pscores (2159, 321, 4) -85057.44\n",
      "MHAttention_pscores_scores (321, 321, 4) 87683.41\n",
      "MHAttention_result_attn (321, 321, 4) 1283.9999\n",
      "MHAttention_result_result_2 (321, 1536) -1017.8952\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Attention scores + position embeddings checks out too (the result does, at least; off by value of 300 though?):\n",
    "relative_position_scores torch.Size([1, 4, 321, 321]) tensor(57733.4141, grad_fn=<SumBackward0>)\n",
    "attention_scores torch.Size([1, 4, 321, 321]) tensor(87989.8203, grad_fn=<SumBackward0>)\n",
    "attention_probs torch.Size([1, 4, 321, 321]) tensor(1283.9999, grad_fn=<SumBackward0>)\n",
    "None torch.Size([1, 321, 1536]) tensor(-1023.2032, grad_fn=<SumBackward0>)\n",
    "'''\n",
    "MHAttention_result_attn = trf_outputs[\"MHAttention_result_attn\"]\n",
    "MHAttention_result_result_2 = trf_outputs[\"MHAttention_result_result_2\"]\n",
    "valueprint(MHAttention_pscores, \"MHAttention_pscores\")\n",
    "valueprint(MHAttention_pscores_scores, \"MHAttention_pscores_scores\")\n",
    "valueprint(MHAttention_result_attn, \"MHAttention_result_attn\")\n",
    "valueprint(MHAttention_result_result_2, \"MHAttention_result_result_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our_selfattn_output torch.Size([1, 321, 1536]) tensor(-1023.2032, grad_fn=<SumBackward0>)\n",
      "MHAttention_result_result_2 (321, 1536) -1017.8952\n"
     ]
    }
   ],
   "source": [
    "valueprint(our_selfattn_output, \"our_selfattn_output\")\n",
    "valueprint(MHAttention_result_result_2, \"MHAttention_result_result_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfAttention_result (321, 1536) -1017.8952\n"
     ]
    }
   ],
   "source": [
    "selfAttention_result = trf_outputs[\"selfAttention_result\"]\n",
    "valueprint(selfAttention_result, \"selfAttention_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfAttention_result_2 (1536, 321) 25.706522\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "arr = result.array();\n",
    "af::saveArray(\"selfAttention_result\", arr, savePathChar, true); \n",
    "\n",
    "result = (*wf_)(transpose(result));\n",
    "\n",
    "arr = result.array();\n",
    "af::saveArray(\"selfAttention_result_2\", arr, savePathChar, true); \n",
    "\n",
    "return result;\n",
    "'''\n",
    "\n",
    "selfAttention_result_2 = trf_outputs[\"selfAttention_result_2\"]\n",
    "valueprint(selfAttention_result_2, \"selfAttention_result_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCTCAttention(\n",
       "  (self): MCTCSelfAttention(\n",
       "    (query): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "    (key): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "    (value): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (distance_embedding): Embedding(1839, 384)\n",
       "  )\n",
       "  (output): MCTCSelfOutput(\n",
       "    (dense): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "    (LayerNorm): MCTCLayerNorm()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_attn = model.mctc.encoder.layers[0].attention\n",
    "our_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None torch.Size([1, 321, 1536]) tensor(330.5734)\n",
      "query_layer torch.Size([1, 4, 321, 384]) tensor(256.1419, grad_fn=<SumBackward0>)\n",
      "key_layer torch.Size([1, 4, 321, 384]) tensor(-1448.2943, grad_fn=<SumBackward0>)\n",
      "value_layer torch.Size([1, 4, 321, 384]) tensor(-995.1271, grad_fn=<SumBackward0>)\n",
      "attention_scores torch.Size([1, 4, 321, 321]) tensor(30256.4258, grad_fn=<SumBackward0>)\n",
      "positional_embedding torch.Size([321, 321, 384]) tensor(101717.8359, grad_fn=<SumBackward0>)\n",
      "relative_position_scores torch.Size([1, 4, 321, 321]) tensor(57733.4141, grad_fn=<SumBackward0>)\n",
      "attention_scores torch.Size([1, 4, 321, 321]) tensor(87989.8203, grad_fn=<SumBackward0>)\n",
      "attention_probs torch.Size([1, 4, 321, 321]) tensor(1283.9999, grad_fn=<SumBackward0>)\n",
      "None torch.Size([1, 321, 1536]) tensor(-618.0341, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "our_attn_output = torch.Tensor(selfAttention_input).unsqueeze(0).transpose(1, 2)\n",
    "valueprint(our_attn_output)\n",
    "our_attn_output = our_attn(our_attn_output)[0]\n",
    "valueprint(our_attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing again after chaning MCTCSelfOutput to this differnt way flashlight seems to do things\n",
    "\n",
    "# testing after fixing the model & weights\n",
    "import torch\n",
    "from transformers import MCTCForCTC, MCTCProcessor, MCTCConfig\n",
    "config = MCTCConfig()\n",
    "model = MCTCForCTC(config)\n",
    "model.load_state_dict(torch.load(\"./ported_pytorch_model.bin\"))\n",
    "model = model.eval()\n",
    "our_attn = model.mctc.encoder.layers[0].attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a deeper look.\n",
    "import arrayfire as af\n",
    "\n",
    "possib_keys = [\"selfAttention_input\", \"selfAttention_posEmb\", \"selfAttention_mask\", \"selfAttention_result\", \"selfAttention_result_2\",\n",
    "\"layer_x\", \"layer_h_preln\", \"layer_h\", \"MHAttention_query\", \"MHAttention_key\", \"MHAttention_value\", \"MHAttention_q\", \"MHAttention_k\", \"MHAttention_v\",\n",
    "\"MHAttention_scores\", \"MHAttention_pscores\", \"MHAttention_pscores_scores\", \"MHAttention_mask\", \"MHAttention_mask_scores\", \"MHAttention_padMaskTile\", \"MHAttention_padMaskTile_scores\",\n",
    "\"MHAttention_result\", \"MHAttention_result_attn\", \"MHAttention_result_result\", \"MHAttention_result_result_2\"]\n",
    "\n",
    "\n",
    "selfAttention_input = af.array.read_array(\"OUTPUT_TRF.arr\", key=\"selfAttention_input\").to_ndarray()\n",
    "MHAttention_result_result = af.array.read_array(\"OUTPUT_TRF.arr\", key=\"MHAttention_result_result\").to_ndarray()\n",
    "MHAttention_result_result_2 = af.array.read_array(\"OUTPUT_TRF.arr\", key=\"MHAttention_result_result_2\").to_ndarray()\n",
    "selfAttention_result_2 = af.array.read_array(\"OUTPUT_TRF.arr\", key=\"selfAttention_result_2\").to_ndarray()\n",
    "layer_x = af.array.read_array(\"OUTPUT_TRF.arr\", key=\"layer_x\").to_ndarray()\n",
    "layer_h = af.array.read_array(\"OUTPUT_TRF.arr\", key=\"layer_h\").to_ndarray()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None torch.Size([1, 321, 1536]) tensor(330.5734)\n",
      "SelfOUtput input torch.Size([1, 321, 1536]) tensor(-1023.2032, grad_fn=<SumBackward0>)\n",
      "SelfOUtput prenorm torch.Size([1, 321, 1536]) tensor(22.9749, grad_fn=<SumBackward0>)\n",
      "SelfOUtput input_tensor torch.Size([1, 321, 1536]) tensor(330.5734)\n",
      "SelfOUtput postnorm torch.Size([1, 321, 1536]) tensor(-618.0341, grad_fn=<SumBackward0>)\n",
      "None torch.Size([1, 321, 1536]) tensor(-618.0341, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def valueprint(arr, key=None):\n",
    "    print(key, arr.shape, arr.sum())\n",
    "our_attn_output = torch.Tensor(selfAttention_input).unsqueeze(0).transpose(1, 2)\n",
    "valueprint(our_attn_output)\n",
    "our_attn_output = our_attn(our_attn_output)[0]\n",
    "valueprint(our_attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfAttention_result_2 (1536, 321) 25.706522\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SelfOUtput prenorm torch.Size([1, 321, 1536]) tensor(22.9749, grad_fn=<SumBackward0>)\n",
    "'''\n",
    "valueprint(selfAttention_result_2, \"selfAttention_result_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_h (1536, 321) -1035.2311\n"
     ]
    }
   ],
   "source": [
    "''' SUPPOSED TO BE THE SAME!\n",
    "\n",
    "auto h = (*norm1_)((f * selfAttention(input)).as(x.type()) + x);\n",
    "af::saveArray(\"layer_h\", h, savePathChar, true); \n",
    "\n",
    "WHERE\n",
    "selfAttention_result_2 = selfAttention(input)\n",
    "f = 1.0\n",
    "\n",
    "SO:\n",
    "h = LayerNorm(selfAttention_result_2 + x)\n",
    "\n",
    "AND:\n",
    "print(\"SelfOUtput prenorm\", hidden_states.shape, hidden_states.sum())\n",
    "\n",
    "hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "print(\"SelfOUtput postnorm\", hidden_states.shape, hidden_states.sum())\n",
    "'''\n",
    "valueprint(layer_h, \"layer_h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_x (1536, 321) 330.57333\n"
     ]
    }
   ],
   "source": [
    "'''[YES] x in fl == input_tensor?\n",
    "SelfOUtput input_tensor torch.Size([1, 321, 1536]) tensor(330.5734)\n",
    "'''\n",
    "valueprint(layer_x, \"layer_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f445f18c7a8bd0fe064b3495835c6fa643dca1e16cc09fc8a4180886f88ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('chanwookim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

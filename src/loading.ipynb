{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from transformers import MCTCForCTC, MCTCConfig\n",
    "\n",
    "config = MCTCConfig()\n",
    "\n",
    "model = MCTCForCTC(config)\n",
    "model.save_pretrained(save_directory=\"./\")\n",
    "model_dict = torch.load(\"pytorch_model.bin\")\n",
    "\n",
    "\n",
    "weights_dict = pickle.load(open(\"./weights_dict.pkl\", \"rb\"))\n",
    "\n",
    "conv_mapper = {\n",
    "    \"normw\": 'mctc.encoder.layer_norm.singleton_weight',\n",
    "    \"normb\": 'mctc.encoder.layer_norm.singleton_bias',\n",
    "    \"filter\": 'mctc.encoder.conv.conv_layers.0.weight',\n",
    "    \"bias\": 'mctc.encoder.conv.conv_layers.0.bias'\n",
    "}\n",
    "mapper = {\n",
    "    'pos': 'attention.self.distance_embedding.weight',\n",
    "    'w1': 'intermediate.dense.weight',\n",
    "    'wq': 'attention.self.query.weight',\n",
    "    'wk': 'attention.self.key.weight',\n",
    "    'wv': 'attention.self.value.weight',\n",
    "    'wf': 'attention.output.dense.weight',\n",
    "    'w2': 'output.dense.weight',\n",
    "    'norm1w': 'attention.output.LayerNorm.weight',\n",
    "    'norm1b': 'attention.output.LayerNorm.bias',\n",
    "    'norm2w': 'output.LayerNorm.weight',\n",
    "    'norm2b': 'output.LayerNorm.bias',\n",
    "}\n",
    "ctc_mapper = {\n",
    "    \"_CTC_head_w\": 'ctc_head.weight',\n",
    "    \"_CTC_head_b\": \"ctc_head.bias\"\n",
    "}\n",
    "\n",
    "def fl_key_to_model_key(idx, fl_key):\n",
    "    if idx < 4:\n",
    "        model_key_mapped = conv_mapper[fl_key.split(\"_\")[-1]]\n",
    "    elif idx < 400:\n",
    "        trf_idx = fl_key.split(\"_\")[1]\n",
    "        trf_key = fl_key.split(\"_\")[2]\n",
    "        mapped = mapper[trf_key]\n",
    "        model_key_mapped = f'mctc.encoder.layers.{trf_idx}.{mapped}'\n",
    "    else:\n",
    "        model_key_mapped = ctc_mapper[fl_key]\n",
    "\n",
    "    return model_key_mapped;\n",
    "\n",
    "def af_fix_then_tensor(param_name, af_array):\n",
    "    tensor = torch.Tensor(af_array)\n",
    "    if param_name == \"Conv2D_filter\":\n",
    "        '''\n",
    "        Conv2D_filter -> mctc.encoder.conv.conv_layers.0.weight\n",
    "        ArrayFire numpy: (7, 1, 80, 3072)\n",
    "        Model Tensor:    torch.Size([3072, 80, 7])\n",
    "        '''\n",
    "        tensor = tensor.squeeze(1) # (7, 80, 3072)\n",
    "        tensor = tensor.transpose(0, 2)\n",
    "        assert tensor.shape == (3072, 80, 7)\n",
    "    if param_name == \"Conv2D_bias\":\n",
    "        '''\n",
    "        Conv2D_bias -> mctc.encoder.conv.conv_layers.0.bias\n",
    "        ArrayFire numpy: (1, 1, 3072)\n",
    "        Model Tensor:    torch.Size([3072])\n",
    "        '''\n",
    "        tensor = tensor.reshape((3072))\n",
    "        assert tensor.shape == (3072,)\n",
    "        \n",
    "    # if \"wf\" in param_name:\n",
    "    #     tensor = tensor.transpose(0,1)\n",
    "    \n",
    "    # if \"norm\" in param_name and \"Conv2D\" in param_name:\n",
    "    #     '''\n",
    "    #     Conv2D_normw -> mctc.encoder.layer_norm.weight\n",
    "    #     ArrayFire numpy: (1,)\n",
    "    #     Model Tensor:    torch.Size([80])\n",
    "\n",
    "    #     Conv2D_normb -> mctc.encoder.layer_norm.bias\n",
    "    #     ArrayFire numpy: (1,)\n",
    "    #     Model Tensor:    torch.Size([80])\n",
    "    #     '''\n",
    "    #     tensor = tensor.tile((80,))\n",
    "    #     assert tensor.shape == (80,)\n",
    "\n",
    "    if \"norm\" in param_name and \"Conv2D\" not in param_name:\n",
    "        '''\n",
    "        Conv2D_normw -> mctc.encoder.layer_norm.weight\n",
    "        ArrayFire numpy: (1,)\n",
    "        Model Tensor:    torch.Size([1536])\n",
    "\n",
    "        Conv2D_normb -> mctc.encoder.layer_norm.bias\n",
    "        ArrayFire numpy: (1,)\n",
    "        Model Tensor:    torch.Size([1536])\n",
    "        '''\n",
    "        tensor = tensor.tile((1536,))\n",
    "        assert tensor.shape == (1536,)\n",
    "    \n",
    "    return tensor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D_normw -> mctc.encoder.layer_norm.singleton_weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1])\n",
      "Model Tensor:             torch.Size([1])\n",
      "\n",
      "Conv2D_normb -> mctc.encoder.layer_norm.singleton_bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1])\n",
      "Model Tensor:             torch.Size([1])\n",
      "\n",
      "Conv2D_filter -> mctc.encoder.conv.conv_layers.0.weight\n",
      "ArrayFire numpy:          (7, 1, 80, 3072)\n",
      "ArrayFire Tensor(fixed):  torch.Size([3072, 80, 7])\n",
      "Model Tensor:             torch.Size([3072, 80, 7])\n",
      "\n",
      "Conv2D_bias -> mctc.encoder.conv.conv_layers.0.bias\n",
      "ArrayFire numpy:          (1, 1, 3072)\n",
      "ArrayFire Tensor(fixed):  torch.Size([3072])\n",
      "Model Tensor:             torch.Size([3072])\n",
      "\n",
      "TRF_0_pos_emb -> mctc.encoder.layers.0.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_0_w1_ -> mctc.encoder.layers.0.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_0_w2_ -> mctc.encoder.layers.0.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_0_wq_ -> mctc.encoder.layers.0.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_0_wk_ -> mctc.encoder.layers.0.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_0_wv_ -> mctc.encoder.layers.0.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_0_wf_ -> mctc.encoder.layers.0.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_0_norm1w_ -> mctc.encoder.layers.0.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_0_norm1b_ -> mctc.encoder.layers.0.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_0_norm2w_ -> mctc.encoder.layers.0.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_0_norm2b_ -> mctc.encoder.layers.0.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_1_pos_emb -> mctc.encoder.layers.1.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_1_w1_ -> mctc.encoder.layers.1.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_1_w2_ -> mctc.encoder.layers.1.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_1_wq_ -> mctc.encoder.layers.1.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_1_wk_ -> mctc.encoder.layers.1.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_1_wv_ -> mctc.encoder.layers.1.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_1_wf_ -> mctc.encoder.layers.1.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_1_norm1w_ -> mctc.encoder.layers.1.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_1_norm1b_ -> mctc.encoder.layers.1.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_1_norm2w_ -> mctc.encoder.layers.1.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_1_norm2b_ -> mctc.encoder.layers.1.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_2_pos_emb -> mctc.encoder.layers.2.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_2_w1_ -> mctc.encoder.layers.2.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_2_w2_ -> mctc.encoder.layers.2.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_2_wq_ -> mctc.encoder.layers.2.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_2_wk_ -> mctc.encoder.layers.2.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_2_wv_ -> mctc.encoder.layers.2.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_2_wf_ -> mctc.encoder.layers.2.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_2_norm1w_ -> mctc.encoder.layers.2.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_2_norm1b_ -> mctc.encoder.layers.2.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_2_norm2w_ -> mctc.encoder.layers.2.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_2_norm2b_ -> mctc.encoder.layers.2.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_3_pos_emb -> mctc.encoder.layers.3.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_3_w1_ -> mctc.encoder.layers.3.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_3_w2_ -> mctc.encoder.layers.3.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_3_wq_ -> mctc.encoder.layers.3.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_3_wk_ -> mctc.encoder.layers.3.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_3_wv_ -> mctc.encoder.layers.3.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_3_wf_ -> mctc.encoder.layers.3.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_3_norm1w_ -> mctc.encoder.layers.3.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_3_norm1b_ -> mctc.encoder.layers.3.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_3_norm2w_ -> mctc.encoder.layers.3.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_3_norm2b_ -> mctc.encoder.layers.3.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_4_pos_emb -> mctc.encoder.layers.4.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_4_w1_ -> mctc.encoder.layers.4.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_4_w2_ -> mctc.encoder.layers.4.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_4_wq_ -> mctc.encoder.layers.4.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_4_wk_ -> mctc.encoder.layers.4.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_4_wv_ -> mctc.encoder.layers.4.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_4_wf_ -> mctc.encoder.layers.4.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_4_norm1w_ -> mctc.encoder.layers.4.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_4_norm1b_ -> mctc.encoder.layers.4.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_4_norm2w_ -> mctc.encoder.layers.4.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_4_norm2b_ -> mctc.encoder.layers.4.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_5_pos_emb -> mctc.encoder.layers.5.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_5_w1_ -> mctc.encoder.layers.5.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_5_w2_ -> mctc.encoder.layers.5.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_5_wq_ -> mctc.encoder.layers.5.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_5_wk_ -> mctc.encoder.layers.5.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_5_wv_ -> mctc.encoder.layers.5.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_5_wf_ -> mctc.encoder.layers.5.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_5_norm1w_ -> mctc.encoder.layers.5.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_5_norm1b_ -> mctc.encoder.layers.5.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_5_norm2w_ -> mctc.encoder.layers.5.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_5_norm2b_ -> mctc.encoder.layers.5.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_6_pos_emb -> mctc.encoder.layers.6.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_6_w1_ -> mctc.encoder.layers.6.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_6_w2_ -> mctc.encoder.layers.6.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_6_wq_ -> mctc.encoder.layers.6.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_6_wk_ -> mctc.encoder.layers.6.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_6_wv_ -> mctc.encoder.layers.6.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_6_wf_ -> mctc.encoder.layers.6.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_6_norm1w_ -> mctc.encoder.layers.6.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_6_norm1b_ -> mctc.encoder.layers.6.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_6_norm2w_ -> mctc.encoder.layers.6.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_6_norm2b_ -> mctc.encoder.layers.6.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_7_pos_emb -> mctc.encoder.layers.7.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_7_w1_ -> mctc.encoder.layers.7.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_7_w2_ -> mctc.encoder.layers.7.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_7_wq_ -> mctc.encoder.layers.7.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_7_wk_ -> mctc.encoder.layers.7.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_7_wv_ -> mctc.encoder.layers.7.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_7_wf_ -> mctc.encoder.layers.7.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_7_norm1w_ -> mctc.encoder.layers.7.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_7_norm1b_ -> mctc.encoder.layers.7.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_7_norm2w_ -> mctc.encoder.layers.7.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_7_norm2b_ -> mctc.encoder.layers.7.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_8_pos_emb -> mctc.encoder.layers.8.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_8_w1_ -> mctc.encoder.layers.8.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_8_w2_ -> mctc.encoder.layers.8.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_8_wq_ -> mctc.encoder.layers.8.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_8_wk_ -> mctc.encoder.layers.8.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_8_wv_ -> mctc.encoder.layers.8.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_8_wf_ -> mctc.encoder.layers.8.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_8_norm1w_ -> mctc.encoder.layers.8.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_8_norm1b_ -> mctc.encoder.layers.8.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_8_norm2w_ -> mctc.encoder.layers.8.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_8_norm2b_ -> mctc.encoder.layers.8.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_9_pos_emb -> mctc.encoder.layers.9.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_9_w1_ -> mctc.encoder.layers.9.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_9_w2_ -> mctc.encoder.layers.9.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_9_wq_ -> mctc.encoder.layers.9.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_9_wk_ -> mctc.encoder.layers.9.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_9_wv_ -> mctc.encoder.layers.9.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_9_wf_ -> mctc.encoder.layers.9.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_9_norm1w_ -> mctc.encoder.layers.9.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_9_norm1b_ -> mctc.encoder.layers.9.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_9_norm2w_ -> mctc.encoder.layers.9.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_9_norm2b_ -> mctc.encoder.layers.9.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_10_pos_emb -> mctc.encoder.layers.10.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_10_w1_ -> mctc.encoder.layers.10.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_10_w2_ -> mctc.encoder.layers.10.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_10_wq_ -> mctc.encoder.layers.10.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_10_wk_ -> mctc.encoder.layers.10.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_10_wv_ -> mctc.encoder.layers.10.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_10_wf_ -> mctc.encoder.layers.10.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_10_norm1w_ -> mctc.encoder.layers.10.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_10_norm1b_ -> mctc.encoder.layers.10.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_10_norm2w_ -> mctc.encoder.layers.10.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_10_norm2b_ -> mctc.encoder.layers.10.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_11_pos_emb -> mctc.encoder.layers.11.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_11_w1_ -> mctc.encoder.layers.11.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_11_w2_ -> mctc.encoder.layers.11.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_11_wq_ -> mctc.encoder.layers.11.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_11_wk_ -> mctc.encoder.layers.11.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_11_wv_ -> mctc.encoder.layers.11.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_11_wf_ -> mctc.encoder.layers.11.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_11_norm1w_ -> mctc.encoder.layers.11.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_11_norm1b_ -> mctc.encoder.layers.11.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_11_norm2w_ -> mctc.encoder.layers.11.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_11_norm2b_ -> mctc.encoder.layers.11.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_12_pos_emb -> mctc.encoder.layers.12.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_12_w1_ -> mctc.encoder.layers.12.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_12_w2_ -> mctc.encoder.layers.12.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_12_wq_ -> mctc.encoder.layers.12.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_12_wk_ -> mctc.encoder.layers.12.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_12_wv_ -> mctc.encoder.layers.12.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_12_wf_ -> mctc.encoder.layers.12.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_12_norm1w_ -> mctc.encoder.layers.12.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_12_norm1b_ -> mctc.encoder.layers.12.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_12_norm2w_ -> mctc.encoder.layers.12.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_12_norm2b_ -> mctc.encoder.layers.12.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_13_pos_emb -> mctc.encoder.layers.13.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_13_w1_ -> mctc.encoder.layers.13.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_13_w2_ -> mctc.encoder.layers.13.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_13_wq_ -> mctc.encoder.layers.13.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_13_wk_ -> mctc.encoder.layers.13.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_13_wv_ -> mctc.encoder.layers.13.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_13_wf_ -> mctc.encoder.layers.13.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_13_norm1w_ -> mctc.encoder.layers.13.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_13_norm1b_ -> mctc.encoder.layers.13.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_13_norm2w_ -> mctc.encoder.layers.13.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_13_norm2b_ -> mctc.encoder.layers.13.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_14_pos_emb -> mctc.encoder.layers.14.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_14_w1_ -> mctc.encoder.layers.14.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_14_w2_ -> mctc.encoder.layers.14.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_14_wq_ -> mctc.encoder.layers.14.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_14_wk_ -> mctc.encoder.layers.14.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_14_wv_ -> mctc.encoder.layers.14.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_14_wf_ -> mctc.encoder.layers.14.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_14_norm1w_ -> mctc.encoder.layers.14.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_14_norm1b_ -> mctc.encoder.layers.14.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_14_norm2w_ -> mctc.encoder.layers.14.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_14_norm2b_ -> mctc.encoder.layers.14.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_15_pos_emb -> mctc.encoder.layers.15.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_15_w1_ -> mctc.encoder.layers.15.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_15_w2_ -> mctc.encoder.layers.15.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_15_wq_ -> mctc.encoder.layers.15.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_15_wk_ -> mctc.encoder.layers.15.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_15_wv_ -> mctc.encoder.layers.15.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_15_wf_ -> mctc.encoder.layers.15.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_15_norm1w_ -> mctc.encoder.layers.15.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_15_norm1b_ -> mctc.encoder.layers.15.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_15_norm2w_ -> mctc.encoder.layers.15.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_15_norm2b_ -> mctc.encoder.layers.15.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_16_pos_emb -> mctc.encoder.layers.16.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_16_w1_ -> mctc.encoder.layers.16.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_16_w2_ -> mctc.encoder.layers.16.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_16_wq_ -> mctc.encoder.layers.16.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_16_wk_ -> mctc.encoder.layers.16.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_16_wv_ -> mctc.encoder.layers.16.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_16_wf_ -> mctc.encoder.layers.16.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_16_norm1w_ -> mctc.encoder.layers.16.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_16_norm1b_ -> mctc.encoder.layers.16.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_16_norm2w_ -> mctc.encoder.layers.16.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_16_norm2b_ -> mctc.encoder.layers.16.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_17_pos_emb -> mctc.encoder.layers.17.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_17_w1_ -> mctc.encoder.layers.17.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_17_w2_ -> mctc.encoder.layers.17.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_17_wq_ -> mctc.encoder.layers.17.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_17_wk_ -> mctc.encoder.layers.17.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_17_wv_ -> mctc.encoder.layers.17.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_17_wf_ -> mctc.encoder.layers.17.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_17_norm1w_ -> mctc.encoder.layers.17.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_17_norm1b_ -> mctc.encoder.layers.17.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_17_norm2w_ -> mctc.encoder.layers.17.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_17_norm2b_ -> mctc.encoder.layers.17.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_18_pos_emb -> mctc.encoder.layers.18.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_18_w1_ -> mctc.encoder.layers.18.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_18_w2_ -> mctc.encoder.layers.18.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_18_wq_ -> mctc.encoder.layers.18.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_18_wk_ -> mctc.encoder.layers.18.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_18_wv_ -> mctc.encoder.layers.18.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_18_wf_ -> mctc.encoder.layers.18.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_18_norm1w_ -> mctc.encoder.layers.18.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_18_norm1b_ -> mctc.encoder.layers.18.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_18_norm2w_ -> mctc.encoder.layers.18.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_18_norm2b_ -> mctc.encoder.layers.18.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_19_pos_emb -> mctc.encoder.layers.19.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_19_w1_ -> mctc.encoder.layers.19.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_19_w2_ -> mctc.encoder.layers.19.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_19_wq_ -> mctc.encoder.layers.19.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_19_wk_ -> mctc.encoder.layers.19.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_19_wv_ -> mctc.encoder.layers.19.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_19_wf_ -> mctc.encoder.layers.19.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_19_norm1w_ -> mctc.encoder.layers.19.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_19_norm1b_ -> mctc.encoder.layers.19.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_19_norm2w_ -> mctc.encoder.layers.19.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_19_norm2b_ -> mctc.encoder.layers.19.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_20_pos_emb -> mctc.encoder.layers.20.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_20_w1_ -> mctc.encoder.layers.20.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_20_w2_ -> mctc.encoder.layers.20.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_20_wq_ -> mctc.encoder.layers.20.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_20_wk_ -> mctc.encoder.layers.20.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_20_wv_ -> mctc.encoder.layers.20.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_20_wf_ -> mctc.encoder.layers.20.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_20_norm1w_ -> mctc.encoder.layers.20.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_20_norm1b_ -> mctc.encoder.layers.20.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_20_norm2w_ -> mctc.encoder.layers.20.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_20_norm2b_ -> mctc.encoder.layers.20.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_21_pos_emb -> mctc.encoder.layers.21.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_21_w1_ -> mctc.encoder.layers.21.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_21_w2_ -> mctc.encoder.layers.21.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_21_wq_ -> mctc.encoder.layers.21.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_21_wk_ -> mctc.encoder.layers.21.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_21_wv_ -> mctc.encoder.layers.21.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_21_wf_ -> mctc.encoder.layers.21.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_21_norm1w_ -> mctc.encoder.layers.21.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_21_norm1b_ -> mctc.encoder.layers.21.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_21_norm2w_ -> mctc.encoder.layers.21.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_21_norm2b_ -> mctc.encoder.layers.21.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_22_pos_emb -> mctc.encoder.layers.22.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_22_w1_ -> mctc.encoder.layers.22.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_22_w2_ -> mctc.encoder.layers.22.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_22_wq_ -> mctc.encoder.layers.22.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_22_wk_ -> mctc.encoder.layers.22.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_22_wv_ -> mctc.encoder.layers.22.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_22_wf_ -> mctc.encoder.layers.22.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_22_norm1w_ -> mctc.encoder.layers.22.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_22_norm1b_ -> mctc.encoder.layers.22.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_22_norm2w_ -> mctc.encoder.layers.22.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_22_norm2b_ -> mctc.encoder.layers.22.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_23_pos_emb -> mctc.encoder.layers.23.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_23_w1_ -> mctc.encoder.layers.23.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_23_w2_ -> mctc.encoder.layers.23.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_23_wq_ -> mctc.encoder.layers.23.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_23_wk_ -> mctc.encoder.layers.23.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_23_wv_ -> mctc.encoder.layers.23.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_23_wf_ -> mctc.encoder.layers.23.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_23_norm1w_ -> mctc.encoder.layers.23.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_23_norm1b_ -> mctc.encoder.layers.23.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_23_norm2w_ -> mctc.encoder.layers.23.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_23_norm2b_ -> mctc.encoder.layers.23.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_24_pos_emb -> mctc.encoder.layers.24.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_24_w1_ -> mctc.encoder.layers.24.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_24_w2_ -> mctc.encoder.layers.24.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_24_wq_ -> mctc.encoder.layers.24.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_24_wk_ -> mctc.encoder.layers.24.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_24_wv_ -> mctc.encoder.layers.24.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_24_wf_ -> mctc.encoder.layers.24.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_24_norm1w_ -> mctc.encoder.layers.24.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_24_norm1b_ -> mctc.encoder.layers.24.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_24_norm2w_ -> mctc.encoder.layers.24.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_24_norm2b_ -> mctc.encoder.layers.24.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_25_pos_emb -> mctc.encoder.layers.25.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_25_w1_ -> mctc.encoder.layers.25.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_25_w2_ -> mctc.encoder.layers.25.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_25_wq_ -> mctc.encoder.layers.25.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_25_wk_ -> mctc.encoder.layers.25.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_25_wv_ -> mctc.encoder.layers.25.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_25_wf_ -> mctc.encoder.layers.25.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_25_norm1w_ -> mctc.encoder.layers.25.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_25_norm1b_ -> mctc.encoder.layers.25.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_25_norm2w_ -> mctc.encoder.layers.25.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_25_norm2b_ -> mctc.encoder.layers.25.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_26_pos_emb -> mctc.encoder.layers.26.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_26_w1_ -> mctc.encoder.layers.26.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_26_w2_ -> mctc.encoder.layers.26.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_26_wq_ -> mctc.encoder.layers.26.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_26_wk_ -> mctc.encoder.layers.26.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_26_wv_ -> mctc.encoder.layers.26.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_26_wf_ -> mctc.encoder.layers.26.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_26_norm1w_ -> mctc.encoder.layers.26.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_26_norm1b_ -> mctc.encoder.layers.26.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_26_norm2w_ -> mctc.encoder.layers.26.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_26_norm2b_ -> mctc.encoder.layers.26.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_27_pos_emb -> mctc.encoder.layers.27.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_27_w1_ -> mctc.encoder.layers.27.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_27_w2_ -> mctc.encoder.layers.27.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_27_wq_ -> mctc.encoder.layers.27.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_27_wk_ -> mctc.encoder.layers.27.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_27_wv_ -> mctc.encoder.layers.27.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_27_wf_ -> mctc.encoder.layers.27.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_27_norm1w_ -> mctc.encoder.layers.27.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_27_norm1b_ -> mctc.encoder.layers.27.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_27_norm2w_ -> mctc.encoder.layers.27.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_27_norm2b_ -> mctc.encoder.layers.27.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_28_pos_emb -> mctc.encoder.layers.28.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_28_w1_ -> mctc.encoder.layers.28.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_28_w2_ -> mctc.encoder.layers.28.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_28_wq_ -> mctc.encoder.layers.28.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_28_wk_ -> mctc.encoder.layers.28.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_28_wv_ -> mctc.encoder.layers.28.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_28_wf_ -> mctc.encoder.layers.28.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_28_norm1w_ -> mctc.encoder.layers.28.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_28_norm1b_ -> mctc.encoder.layers.28.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_28_norm2w_ -> mctc.encoder.layers.28.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_28_norm2b_ -> mctc.encoder.layers.28.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_29_pos_emb -> mctc.encoder.layers.29.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_29_w1_ -> mctc.encoder.layers.29.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_29_w2_ -> mctc.encoder.layers.29.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_29_wq_ -> mctc.encoder.layers.29.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_29_wk_ -> mctc.encoder.layers.29.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_29_wv_ -> mctc.encoder.layers.29.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_29_wf_ -> mctc.encoder.layers.29.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_29_norm1w_ -> mctc.encoder.layers.29.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_29_norm1b_ -> mctc.encoder.layers.29.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_29_norm2w_ -> mctc.encoder.layers.29.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_29_norm2b_ -> mctc.encoder.layers.29.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_30_pos_emb -> mctc.encoder.layers.30.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_30_w1_ -> mctc.encoder.layers.30.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_30_w2_ -> mctc.encoder.layers.30.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_30_wq_ -> mctc.encoder.layers.30.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_30_wk_ -> mctc.encoder.layers.30.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_30_wv_ -> mctc.encoder.layers.30.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_30_wf_ -> mctc.encoder.layers.30.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_30_norm1w_ -> mctc.encoder.layers.30.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_30_norm1b_ -> mctc.encoder.layers.30.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_30_norm2w_ -> mctc.encoder.layers.30.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_30_norm2b_ -> mctc.encoder.layers.30.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_31_pos_emb -> mctc.encoder.layers.31.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_31_w1_ -> mctc.encoder.layers.31.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_31_w2_ -> mctc.encoder.layers.31.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_31_wq_ -> mctc.encoder.layers.31.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_31_wk_ -> mctc.encoder.layers.31.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_31_wv_ -> mctc.encoder.layers.31.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_31_wf_ -> mctc.encoder.layers.31.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_31_norm1w_ -> mctc.encoder.layers.31.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_31_norm1b_ -> mctc.encoder.layers.31.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_31_norm2w_ -> mctc.encoder.layers.31.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_31_norm2b_ -> mctc.encoder.layers.31.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_32_pos_emb -> mctc.encoder.layers.32.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_32_w1_ -> mctc.encoder.layers.32.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_32_w2_ -> mctc.encoder.layers.32.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_32_wq_ -> mctc.encoder.layers.32.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_32_wk_ -> mctc.encoder.layers.32.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_32_wv_ -> mctc.encoder.layers.32.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_32_wf_ -> mctc.encoder.layers.32.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_32_norm1w_ -> mctc.encoder.layers.32.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_32_norm1b_ -> mctc.encoder.layers.32.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_32_norm2w_ -> mctc.encoder.layers.32.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_32_norm2b_ -> mctc.encoder.layers.32.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_33_pos_emb -> mctc.encoder.layers.33.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_33_w1_ -> mctc.encoder.layers.33.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_33_w2_ -> mctc.encoder.layers.33.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_33_wq_ -> mctc.encoder.layers.33.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_33_wk_ -> mctc.encoder.layers.33.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_33_wv_ -> mctc.encoder.layers.33.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_33_wf_ -> mctc.encoder.layers.33.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_33_norm1w_ -> mctc.encoder.layers.33.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_33_norm1b_ -> mctc.encoder.layers.33.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_33_norm2w_ -> mctc.encoder.layers.33.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_33_norm2b_ -> mctc.encoder.layers.33.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_34_pos_emb -> mctc.encoder.layers.34.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_34_w1_ -> mctc.encoder.layers.34.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_34_w2_ -> mctc.encoder.layers.34.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_34_wq_ -> mctc.encoder.layers.34.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_34_wk_ -> mctc.encoder.layers.34.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_34_wv_ -> mctc.encoder.layers.34.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_34_wf_ -> mctc.encoder.layers.34.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_34_norm1w_ -> mctc.encoder.layers.34.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_34_norm1b_ -> mctc.encoder.layers.34.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_34_norm2w_ -> mctc.encoder.layers.34.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_34_norm2b_ -> mctc.encoder.layers.34.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_35_pos_emb -> mctc.encoder.layers.35.attention.self.distance_embedding.weight\n",
      "ArrayFire numpy:          (1839, 384)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1839, 384])\n",
      "Model Tensor:             torch.Size([1839, 384])\n",
      "\n",
      "TRF_35_w1_ -> mctc.encoder.layers.35.intermediate.dense.weight\n",
      "ArrayFire numpy:          (6144, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([6144, 1536])\n",
      "Model Tensor:             torch.Size([6144, 1536])\n",
      "\n",
      "TRF_35_w2_ -> mctc.encoder.layers.35.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 6144)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 6144])\n",
      "Model Tensor:             torch.Size([1536, 6144])\n",
      "\n",
      "TRF_35_wq_ -> mctc.encoder.layers.35.attention.self.query.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_35_wk_ -> mctc.encoder.layers.35.attention.self.key.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_35_wv_ -> mctc.encoder.layers.35.attention.self.value.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_35_wf_ -> mctc.encoder.layers.35.attention.output.dense.weight\n",
      "ArrayFire numpy:          (1536, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536, 1536])\n",
      "Model Tensor:             torch.Size([1536, 1536])\n",
      "\n",
      "TRF_35_norm1w_ -> mctc.encoder.layers.35.attention.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_35_norm1b_ -> mctc.encoder.layers.35.attention.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_35_norm2w_ -> mctc.encoder.layers.35.output.LayerNorm.weight\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "TRF_35_norm2b_ -> mctc.encoder.layers.35.output.LayerNorm.bias\n",
      "ArrayFire numpy:          (1,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([1536])\n",
      "Model Tensor:             torch.Size([1536])\n",
      "\n",
      "_CTC_head_w -> ctc_head.weight\n",
      "ArrayFire numpy:          (8065, 1536)\n",
      "ArrayFire Tensor(fixed):  torch.Size([8065, 1536])\n",
      "Model Tensor:             torch.Size([8065, 1536])\n",
      "\n",
      "_CTC_head_b -> ctc_head.bias\n",
      "ArrayFire numpy:          (8065,)\n",
      "ArrayFire Tensor(fixed):  torch.Size([8065])\n",
      "Model Tensor:             torch.Size([8065])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, fl_key in enumerate(weights_dict.keys()):\n",
    "    if \"LID\" in fl_key:\n",
    "        break\n",
    "\n",
    "    model_key_mapped = fl_key_to_model_key(idx, fl_key)\n",
    "\n",
    "    print(fl_key, \"->\", model_key_mapped)\n",
    "    orig_tensor = model_dict[model_key_mapped]\n",
    "    fl_tensor = weights_dict[fl_key]\n",
    "    fixed_tensor = af_fix_then_tensor(fl_key, fl_tensor)\n",
    "    assert fixed_tensor.shape == orig_tensor.shape\n",
    "    print(\"ArrayFire numpy:         \", fl_tensor.shape)\n",
    "    print(\"ArrayFire Tensor(fixed): \", fixed_tensor.shape)\n",
    "    print(\"Model Tensor:            \", orig_tensor.shape)\n",
    "    print()\n",
    "\n",
    "# testing above mapper with tensor shapes\n",
    "# testing above mapper with tensor shapes\n",
    "model_dict_keys = list(model_dict.keys())\n",
    "mapped_keys = []\n",
    "for idx, fl_key in enumerate(weights_dict.keys()):\n",
    "    if \"LID\" in fl_key:\n",
    "        break\n",
    "\n",
    "    model_key_mapped = fl_key_to_model_key(idx, fl_key)\n",
    "\n",
    "\n",
    "    fl_tensor = weights_dict[fl_key]\n",
    "    fixed_tensor = af_fix_then_tensor(fl_key, fl_tensor)\n",
    "\n",
    "    model_dict[model_key_mapped] = fixed_tensor\n",
    "    \n",
    "    mapped_keys.append(model_key_mapped)\n",
    "# confirming we mapped everything -> and <- \n",
    "assert len(mapped_keys) == len(model_dict_keys)\n",
    "assert set(mapped_keys) == set(model_dict_keys)\n",
    "torch.save(model_dict, \"ported_pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrayfire as af\n",
    "\n",
    "# in order\n",
    "keys = [\n",
    "    \"model_input\",\n",
    "    \"conv_output\", \"misc_padMask\",\n",
    "] \n",
    "for i in range(36):\n",
    "    keys.append(f\"trf_input_{i}\")\n",
    "    keys.append(f\"trf_output_{i}\")\n",
    "\n",
    "keys = keys + [\n",
    "    \"ctc_head_input\",\n",
    "    \"ctc_head_output\"\n",
    "]\n",
    "    \n",
    "lookup = {}\n",
    "for key in keys:\n",
    "    arr = af.array.read_array(\"OUTPUT.arr\", key=key).to_ndarray()\n",
    "    lookup[key] = arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_input (961, 80)\n",
      "[-2.0350985527038574, -2.0350985527038574, -2.0350985527038574]\n",
      "[-2.0350985527038574, -2.0350985527038574, -2.0350985527038574]\n",
      "[-2.0350985527038574, -2.0350985527038574, -2.0350985527038574]\n",
      "[-2.0350985527038574, -2.0350985527038574, -2.0350985527038574]\n",
      "[-2.0350985527038574, -2.0350985527038574, -2.0350985527038574]\n",
      "[-0.8471124172210693, -0.38888654112815857, -0.11196883767843246]\n",
      "[-0.6358304619789124, -0.6489655375480652, -0.6837743520736694]\n",
      "[-0.2124035656452179, -0.21033309400081635, -0.21287468075752258]\n",
      "[-0.7262757420539856, -0.5959850549697876, -0.4422873258590698]\n",
      "[-0.5001829266548157, -0.5467087030410767, -0.6760406494140625]\n",
      "[-0.3086141049861908, -0.2965729832649231, -0.28046396374702454]\n",
      "[-0.4022613763809204, -0.45817720890045166, -0.6230398416519165]\n",
      "[-0.3147038519382477, -0.23073029518127441, -0.11785335838794708]\n",
      "[-0.3470221757888794, -0.28721654415130615, -0.2011248767375946]\n",
      "[-0.8904579281806946, -0.53175288438797, -0.27561914920806885]\n"
     ]
    }
   ],
   "source": [
    "model_input = lookup[\"model_input\"]\n",
    "print(\"model_input\", model_input.shape)\n",
    "model_input = model_input.tolist()\n",
    "for item in model_input[:5] + model_input[400:405] + model_input[900:905]:\n",
    "    print(item[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a938afcde0498eaca4b5f58bdece4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MCTCForCTC, MCTCProcessor\n",
    "\n",
    "model = MCTCForCTC.from_pretrained(\"cwkeam/mctc-large\")\n",
    "processor = MCTCProcessor.from_pretrained(\"cwkeam/mctc-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Audio, Dataset\n",
    "\n",
    "my_dataset = Dataset.from_dict({\"audio\": [\"./audio/audio.flac\"]})\n",
    "audio_sample = my_dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "audio_arrays = [x[\"array\"] for x in audio_sample[\"audio\"]]\n",
    "inputs = processor(\n",
    "    audio_arrays, sampling_rate=16_000, max_length=16000, truncation=True\n",
    ")\n",
    "hf_inputs = torch.Tensor(inputs[\"input_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([961, 80])\n",
      "torch.Size([1, 15401, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31755/3533686471.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  real_inputs = torch.Tensor(inputs[\"input_features\"])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "real_inputs = torch.Tensor(inputs[\"input_features\"])\n",
    "model_input = torch.Tensor(model_input)\n",
    "print(model_input.shape)\n",
    "print(real_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_size 80\n",
      "feature_size 10\n",
      "feature_size 25\n",
      "mel_specgram torch.Size([80, 15401])\n",
      "torch.Size([15401, 80])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import MCTCForCTC, MCTCProcessor\n",
    "from datasets import load_dataset, load_metric, Audio, Dataset\n",
    "\n",
    "my_dataset = Dataset.from_dict({\"audio\": [\"./audio/audio.flac\"]})\n",
    "audio_sample = my_dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "# model = MCTCForCTC.from_pretrained(\"cwkeam/mctc-large\")\n",
    "processor = MCTCProcessor.from_pretrained(\"cwkeam/mctc-large\")\n",
    "print(\"feature_size\", processor.feature_extractor.feature_size)\n",
    "print(\"feature_size\", processor.feature_extractor.hop_length)\n",
    "print(\"feature_size\", processor.feature_extractor.win_length)\n",
    "# processor.feature_extractor.normalize_means=False\n",
    "audio_arrays = [x[\"array\"] for x in audio_sample[\"audio\"]]\n",
    "inputs = processor(\n",
    "    audio_arrays, sampling_rate=16_000, max_length=16_000, truncation=True\n",
    ")\n",
    "real_inputs = torch.Tensor(inputs[\"input_features\"][0])\n",
    "print(real_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3214, -0.3214, -0.3238, -0.3238, -0.3277])\n",
      "tensor([-2.0351, -2.0351, -2.0351, -2.0351, -2.0351])\n",
      "\n",
      "tensor([-0.3214, -0.3214, -0.3238, -0.3238, -0.3277])\n",
      "tensor([-2.0351, -2.0351, -2.0351, -2.0351, -2.0351])\n",
      "\n",
      "tensor([-0.3214, -0.3214, -0.3238, -0.3238, -0.3277])\n",
      "tensor([-2.0351, -2.0351, -2.0351, -2.0351, -2.0351])\n",
      "\n",
      "tensor([-0.3214, -0.3214, -0.3238, -0.3238, -0.3277])\n",
      "tensor([-2.0351, -2.0351, -2.0351, -2.0351, -2.0351])\n",
      "\n",
      "tensor([-0.3214, -0.3214, -0.3238, -0.3238, -0.3277])\n",
      "tensor([-2.0351, -2.0351, -2.0351, -2.0351, -2.0351])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_input = torch.Tensor(model_input)\n",
    "for i in range(5):\n",
    "    print(real_inputs[i][:5])\n",
    "    print(model_input[i][:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f445f18c7a8bd0fe064b3495835c6fa643dca1e16cc09fc8a4180886f88ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('chanwookim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
